---
title: "Project-4"
author: "Hannes Gubler"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output: 
  bookdown::html_document2:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE, message = FALSE)
```

# Introduction

The U.S. Presidential elections are one of the most significant political events in the world and draw attention from all across the globe. The elections, which take place every four years, determine the president of the United States for the next four years. In contrary to most other countries, there is not a single nationwide election. Instead, it is a series of separate state-level elections, which then are combined to determine the winner. Each state has a certain number of "electoral votes" that are (more or less) based on its population and the candidate with the most votes in a given state wins all of that state's electoral votes.

In this report, we explore the data on U.S. Presidential elections between 1948 and 1992, focusing on the two-party vote for the Democratic and Republican candidates in each state and year. We try to model the share of Democratic votes in a given state and year first with a linear model and later with a linear mixed model. By analyzing the data, we aim to identify crucial factors that lead to electoral success in the United States. Furthermore we investigate how we can apply the linear mixed model to the data to overcome the independence assumption of the linear model.

# Data Explanation

To model the share of Democratic votes in a given state and year, we have the following variables available.

* `dvote` - the outcome variable, the Democratic party candidate's share of the vote in the given state and year
* `year` - specifies the year of the election
* `state` - specifies the state of the corresponding outcome variable

Additionally we have the nationwide variables

* `dvote_poll` - the nationwide Democratic party candidate's share of the vote in the September poll
* `dapprove_inc` - the nationwide presidential approval in the July poll (negative values for Republic presidents and positive values for Democratic presidents)
* `dapprove_presinc` - same as `dapprove_inc` but equals 0 if the current president is not running for a re-election
* `gnp_growth_inc` - the statewide GNP growth in the second quarter (positive values if the incumbent president is a Democrat and negative if the incumbent president is a Republican)

Furthermore we have the state wide variables

* `dvote_last` - the Democratic party candidate's share of the last election given state and year (as a deviation from corresponding national vote)
* `dvote_last2` - the Democratic party candidate's share two elections ago given state and year (as a deviation from corresponding national vote)
* `home_state` - the home state of the presidential candidate (+1 if the corresponding state is the home state of the Democratic candidate and -1 if the corresponding state is the home state of the Republican candidate)
* `home_state_vice` - the home state of the vice-presidential candidate (+1 if the corresponding state is the home state of the Democratic vice candidate and -1 if the corresponding state is the home state of the Republican vice candidate)
* `dmajor_leg` - the Democratic majority in the state legislature (positive values if the Democrats had a majority compared to the Republicans and negative values if the Republicans had a majority compared to the Democrats)
* `econ_growth_inc` - the state economic growth in the past year (positive values if the incumbent president is a Democrat and negative if the incumbent president is a Republican)
* `state_ideology` - a measure for the state ideology (same value in every year) (positive values if ideology is more Democratic and negative values if ideology is more Republic)
* `ideology_comp` - ideological compatibility of a given state with the candidates 
* `cath_1960` - proportion of Catholics in 1960 compared to U.S. average and 0 in any other year (1960 had a Catholic presidential candidate)

Lastly we have the regional variables 

* `south` - south indicator
* `south_1964` - south indicator in 1964
* `deep_south_1964` - deep south indicator in 1964
* `new_england_1964` - New England indicator in 1964
* `new_england_1972` - New England indicator in 1972
* `west_1976` - west indicator in 1976


The year 1964 was special because the Democratic candidate was able to completely dominate the elections, also in the south but with an exception of the deep south states. The other regional variables (`south`, `new_england_1972`, `west_1976`) are there to adjust for known and expected outliers (very unusual results in certain states and years) instead of removing them from the data.

In our analysis we will treat `year`, `state` as well as all the regional variables as factors, while the remaining variables will be treated as numerical. Furthermore we add an additional factor `region` to the dataset dividing the states in the regions "Northeast", "South", "Midwest" and "West. Lastly we remove all the observation with missing values from our data.

```{r preprocessing}
library("readr") # to load data
library("tidyverse")
library("ggpubr") # for ggarrange
library("car") # type 2 anova
library("knitr") #Â to print tables
library("lme4") # for mixed models
data <- read_table("Data/4_US_elections.txt")
data = data %>% select(-constant) # remove manually added intercept
# change mentioned variables to factors
data = data %>% 
  mutate(year = as.factor(year),
                       state = as.factor(state), 
                       r1 = as.factor(r1), 
                       r2 = as.factor(r2), 
                       r3 = as.factor(r3), 
                       r4 = as.factor(r4), 
                       r5 = as.factor(r5), 
                       r6 = as.factor(r6), )

# rename the variables
data = data %>% 
  rename(dvote = Dvote,
         dvote_poll = n1,
         dapprove_inc = n2,
         dapprove_presinc = n3,
         gnp_growth_inc = n4,
         dvote_last = s1,
         dvote_last2 = s2,
         home_state = s3,
         home_state_vice = s4,
         dmajor_leg = s5,
         econ_growth_inc = s6,
         state_ideology = s7,
         ideology_comp = s8,
         cath_1960 = s9,
         south = r1,
         south_1964 = r2,
         deep_south_1964 = r3,
         new_england_1964 = r4,
         new_england_1972 = r5,
         west_1976 = r6)

# create a region variable
northeast = c(7, 8, 19, 20, 21, 29, 30, 32, 38, 39, 45, 48)
south = c(1, 4, 9, 10, 17, 18, 24, 33, 36, 40, 42, 43, 46)
midwest = c(13, 14, 15, 16, 22, 23, 25, 27, 34, 35, 41, 49)
west = c(2, 3, 5, 6, 11, 12, 26, 28, 31, 37, 44, 47, 50)

data$region = ifelse(data$state %in% northeast, "northeast",
                      ifelse(data$state %in% south, "south",
                             ifelse(data$state %in% midwest, "midwest",
                                    ifelse(data$state %in% west, "west", NA))))
data = data %>% mutate(region = as.factor(region))
data = na.omit(data)
```

# Linear Model {#linmod}

For our first linear model, we certainly want to include `state` to predict `dvote`. Since `state` is a factor variable, we can not include the factor `region` to the same model since it would make the design matrix singular. The same goes for `state_ideology`, which does not change over the years and hence is the same number for two observations from the same state (and thus makes the design matrix singular since we already include `state`). Similarly, we want to include the factor `year` in our first model, which will not allow us to use any of the nationwide variables, since a nationwide variable takes the same value for all observations from one year.
So our linear model uses the predictors `dvote_last`, `dvote_last2`, `home_state`, `home_state_vice`, `dmajor_leg`, `econ_growth_inc`, `ideology_comp`, `cath_1960`, `south`, `south_1964`, `deep_south_1964`, `new_england_1964`, `new_england_1972` and `west_1976` to model the response `dvote`. First we look at the type two anova test for our linear model, which compares for each coefficient the full model vs the model with all predictors but not the one corresponding to the specific coefficient.

```{r anova}
# create model described as above
m0 = lm(dvote ~ . 
        - evotes 
        - region 
        - state_ideology 
        - dvote_poll 
        - dapprove_inc
        - dapprove_presinc 
        - gnp_growth_inc, 
        data = data)
# perform type 2 anova and print results in a table
anova = Anova(m0, type = 2)
kable(anova[1:16, ], digits = 3, caption = "Type 2 anova for the linear model, comparing for each coefficient the full model with the full model excluding the predictor from that coefficient.")
```
Except `ideology_comp` all the coefficients seem to be important, so we keep all the predictors from before but remove `ideology_comp` from our model.

Next we look at the residuals vs fitted values and normal Q-Q plots of our linear model.

```{r diagnostics, fig.width=7, fig.height=3.5, fig.cap="Residuals vs fitted values (left) and normal Q-Q plot (right) of our linear model."}
# fit the same model as before but exclude ideology_comp
m1 = lm(dvote ~ . 
        - evotes 
        - region 
        - state_ideology 
        - dvote_poll 
        - dapprove_inc
        - dapprove_presinc 
        - gnp_growth_inc
        - ideology_comp, 
        data = data)
# create a data frame that contains residuals, standardized residuals and fitted values for plots
data_res = data
data_res$residuals = resid(m1)
data_res$std_residuals = rstandard(m1)
data_res$fitted = m1$fitted.values
# create residuals vs fitted values plot
res_vs_fit = ggplot(data_res, aes(x = fitted, y = residuals)) + 
  geom_point() + 
  labs(x = "fitted values", y = "residuals") + 
  ggtitle("Residuals vs Fitted Values")
# create qq plot
qq_plot = ggplot(data_res, aes(sample = std_residuals)) +
  stat_qq() + 
  stat_qq_line() + 
  labs(x = "theoretical quantiles", y = "standardized residuals quantiles") + 
  ggtitle("Normal Q-Q Plot")
# plot residuals vs fitted values (left) and qqplot (right)
ggarrange(res_vs_fit, qq_plot, ncol = 2, nrow = 1)
```
The normal Q-Q plot looks fine with only slight abbreviations in the tails, so the normality assumption looks passable. Additionally we do not observe a clear pattern in the residuals vs fitted values plot, suggesting that the independence assumption could hold. However, it is still possible that we have dependence between observations inside specific groups, for example observations from the same year or the same region could influence each other.

```{r onelvlgroup, fig.height=3.5, fig.width=9, fig.cap="Boxplots of the residuals of our linear model grouped by year (left) and grouped by region (right)."}
# create boxplots of residuals grouped by region
year_res_plot = ggplot(mapping = aes(y = residuals, col = year), data = data_res) + 
  geom_boxplot() + 
  ggtitle("Boxplots of Residuals by Year")
# create boxplots of residuals grouped by region
region_res_plot = ggplot(mapping = aes(y = residuals, col = region), data = data_res) +
  geom_boxplot() + 
    ggtitle("Boxplots of Residuals by Region")
# arrange the two plots in a 1x2 grid
ggarrange(year_res_plot, region_res_plot, nrow = 1, ncol = 2)
```

The residuals still look acceptable as we do not observe groups that substantially exceed the region around zero. Another point to consider is the dependence of observations from the same year and the same region. Possibly in a specific year, states in the same region tend to influence each other.

```{r twolvlgroup, fig.height=5, fig.width=9, fig.cap="For each region the corresponding plot shows boxplots of the residuals corresponding to the same year."}
# create dataframes with residuals for each region
data_northeast = data_res[data_res$region == "northeast", ]
data_south = data_res[data_res$region == "south", ]
data_midwest = data_res[data_res$region == "midwest", ]
data_west = data_res[data_res$region == "west", ]
# create residuals plot for each region grouped by year
northeast_res_plot = ggplot(mapping=aes(y=residuals, col=year), data = data_northeast) +
  geom_boxplot() + 
  ggtitle("Northeast Residuals by Year")
south_res_plot = ggplot(mapping=aes(y=residuals, col=year), data = data_south) +
  geom_boxplot() +
  ggtitle("South Residuals by Year")
midwest_res_plot = ggplot(mapping=aes(y=residuals, col=year), data = data_midwest) +
  geom_boxplot() +
  ggtitle("Midwest Residuals by Year")
west_res_plot = ggplot(mapping=aes(y=residuals, col=year), data = data_west) +
  geom_boxplot() +
  ggtitle("West Residuals by Year")
# plot results
ggarrange(northeast_res_plot, south_res_plot, midwest_res_plot, west_res_plot, 
          ncol = 2, nrow = 2, common.legend = TRUE, legend = "right")
```

Now we observe a grouping effect. It looks like the distribution of the residuals within one region from the same year is not centered around zero. This suggests that observations within one region and year may be dependent, violating a crucial assumption of the linear model. Therefore it could be useful to model the data with a linear mixed model, where we can allow for dependency between certain observations.

# Linear Mixed Model

The linear mixed model is an extension of the linear model. We define it as
$$
Y = X\beta + Z b + \epsilon, \quad b \sim N_q(0,C), \quad \epsilon \sim N_n(0, \sigma^2I_n)
$$
where $X \in \mathbb{R}^{n\times p}$ and $Z \in \mathbb{R}^{n\times q}$ are known design matrices, $\beta \in \mathbb{R}^p$ are fixed parameters (effects), $b \in \mathbb{R}^q$ are random effects (independent of $\epsilon$) and $Y \in \mathbb{R}^n$ is the response. So the parameters in a linear mixed model are $\beta, C$ and $\sigma^2$. They are estimated either by using maximum likelihood (ML) or restricted maximum likelihood (REML). In our analysis we use the ML method, so we will be able to use the likelihood ratio test for fixed effects. The inclusion of the random effect $b$ in the model allows for the modeling of the correlation structure among the observations. In the case of factor variables, the random effect $b$ captures the deviation of the observations within a group from the overall population mean (fixed effect). Moreover the covariance matrix $C$ of $b$ can allow for correlation between different random effects

As observed in Figure (\@ref(fig:twolvlgroup)) we would like to allow for dependency between observations from the same year and region. So we add a random effect for the interaction between `year` and `region` to our linear model from the section before. Furthermore we also add a random effect for `year` itself as it intuitively makes sense to allow for correlation between observations from the same year. In the R syntax, we add the term `(1|year/region)` to our linear model and fit it with the `lmer` function from the `lme4` library. We have the relationship `(1|year/region) = (1|year) + (1|year:region)`, which adds a random intercept for `year` and regions within years `region:year` to our model. Note that since we add a random effect for `year` to our model we remove the fixed effect of `year` because we do not want to have both a fixed and random effect for `year` at the same time. But then, not having a fixed effect for `year` in the model allows us to use the nationwide variables that we excluded before, as we do not have singularity problems anymore. Figure (\@ref(fig:mixedm0)) now shows the same plot as in Figure (\@ref(fig:twolvlgroup)) but with the residuals from the mixed model to see if we solved the issue.

```{r mixedm0, fig.cap="For each region the corresponding plot shows boxplots of the residuals from the mixed model corresponding to the same year."}
# create mixed model with random intercept for year and year:region
mixed_m1 = lmer(dvote ~ . 
                - evotes 
                - region 
                - state_ideology 
                - ideology_comp 
                - year
                + (1|year)
                + (1|year:region), 
                REML = FALSE,
                data = data)
# create dataframes with residuals for each to replicate plot from before 
# with residuals grouped by year and region
data_res_mixed = data_res
data_res_mixed$residuals = resid(mixed_m1)
data_northeast_mixed = data_res_mixed[data_res_mixed$region == "northeast", ]
data_south_mixed = data_res_mixed[data_res_mixed$region == "south", ]
data_midwest_mixed = data_res_mixed[data_res_mixed$region == "midwest", ]
data_west_mixed = data_res_mixed[data_res_mixed$region == "west", ]
# create plots for each region
northeast_res_plot = ggplot(mapping=aes(y=residuals, col=year), data = data_northeast_mixed) +
  geom_boxplot() + 
  ggtitle("Northeast Residuals by Year")
south_res_plot = ggplot(mapping=aes(y=residuals, col=year), data = data_south_mixed) +
  geom_boxplot() +
  ggtitle("South Residuals by Year")
midwest_res_plot = ggplot(mapping=aes(y=residuals, col=year), data = data_midwest_mixed) +
  geom_boxplot() +
  ggtitle("Midwest Residuals by Year")
west_res_plot = ggplot(mapping=aes(y=residuals, col=year), data = data_west_mixed) +
  geom_boxplot() +
  ggtitle("West Residuals by Year")
# plot results
ggarrange(northeast_res_plot, south_res_plot, midwest_res_plot, west_res_plot, 
          ncol = 2, nrow = 2, common.legend = TRUE, legend = "right")
```
The distribution of the residuals within one year and region looks much better, suggesting that adding the random effects to the model was useful. But could we not just include a fixed effect for `year` and the interaction between `year` and `region` to the linear model instead of moving to mixed models? In fact, Figure (\@ref(fig:mixedm0)) looks quite similar if we include `year` and the interaction as fixed effects instead of as random effects, meaning that also in this case the groups of the residuals are much more centered around zero than in Figure (\@ref(fig:twolvlgroup)). Still, this might not be the best idea as it adds another 48 coefficients to our model (12 years times 4 regions), where our dataset contains only a few more than 500 observations. Having too many coefficients in a model blows up the standard errors of these coefficients. In our case, we are not even able to fit all the coefficients for the interaction between `year` and `region` due to singularity issues of the design matrix. This justifies why we proceed with the linear mixed model.

Next we test if we can reduce part of the random effect structure of our model, specifically we test if we can exclude the random intercept for `year`. In Figure (\@ref(fig:onelvlgroup)) we do not observe a clear dependence in observations from the same year, suggesting that there is possibly no need for a random intercept for `year`. To test this assumption we use parametric bootstrap rather than an anova model submodel test. The reason for that is because as the random effects are constraint, they are not taking one degree of freedom per effect, but a bit less. Hence we can not easily determine the exact number of degrees of freedom of the asymptotic chi square distribution of the likelihood ratio test. Thus we use parametric bootstrap, where we do not need to know the distribution of the likelihood ratio test. In the following we denote the full model with random intercept for `year` and `year:region` as `mixed_m1` ($H_1$) and the model where we remove the random intercept for `year` as `mixed_m0` ($H_0$). We then proceed as follows to test $H_0$ vs $H_1$.

* Calculate the likelihood ratio statistic $\text{lr}$ of `mixed_m0` and `mixed_m1`.
* Repeat the below $n$ times.
  - Simulate the response `dvote_boot` from `mixed_m0` and the data.
  - Fit the models `mixed_m0_boot` and `mixed_m1_boot` the same way as `mixed_m0` and `mixed_m1` respectively, but use `dvote_boot` as response.
  - Calculate the likelihood ratio statistic $\text{lr}_{\text{boot}}$ of `mixed_m0_boot` and `mixed_m1_boot`.

If we denote $\text{lr}_{\text{boot}}^i$ as the likelihood ratio statistic from the $i$-th bootstrap we estimate the p-value for testing $H_0$ vs $H_1$ as 
$$
p = \frac{1}{n}\sum_{i=1}^n \mathbb{1}_{\{\text{lr}_{\text{boot}}^i > \text{lr}\}}.
$$

```{r parametric bootstrap}
# the calculations for the parametric bootstrap can be found in the separate script
# called bootstrap_script.R
```

Once we perform these calculations with $n = 1000$ we get a p-value of $0.598$, suggesting that it is not necessary to include `year` as a random effect in our model and hence we can discard part of the random effect structure. So we proceed with the model with a random effect only for the interaction between `year` and `region`. 

For the fixed effects, we look at the type two anova test. Since we only test for fixed effects, the likelihood ratio test follows chi square distribution asymptotically where we can determine the degrees of freedom as usual. Note that we fit our linear mixed model using ML such that we can make use of the likelihood ratio test (which bases on the fact that parameters have been estimated using maximum likelihood).

```{r anova2}
# create model without random intercept for year according to the results of 
# parametric bootstrap
mixed_m0 = lmer(dvote ~ 
                + state 
                + dvote_poll 
                + dapprove_inc 
                + dapprove_presinc 
                + gnp_growth_inc 
                + dvote_last 
                + dvote_last2 
                + home_state 
                + home_state_vice 
                + dmajor_leg 
                + econ_growth_inc 
                + cath_1960 
                + south 
                + south_1964 
                + deep_south_1964 
                + new_england_1964 
                + new_england_1972 
                + west_1976 
                + (1|year:region),
                data = data, 
                REML = FALSE)
# create anova type 2 table for the model above
anova2 = Anova(mixed_m0, type = 2, data = data)
kable(anova2, digits = 3, caption = "Type two anova for the fixed effects in our linear mixed model, comparing for each coefficient the full model with the full model excluding the predictor from that coefficient.")
```
According to the type 2 anova test, only `dapprove_inc` seems to be not statistically significant at a level 0.05. `dapprove_presinc` is exactly the same as `dapprove_inc` if the incumbent president is running for a re-election and zero else, so this result suggests that the support for the incumbent president does not matter to predict `dvote` if he is not running for a re-election. Thus, as a last step, we remove `dapprove_inc` from our linear mixed model.

To conclude, our last model now consists of the fixed effects present in Table (\@ref(tab:anova2)), except `dapprove_inc`, and a random effect for the interaction between `year` and `region`. In the next section, we look at some of the most important diagnostic tools for our linear mixed model. 

## Random Effect Diagnostics

The model diagnostics for a linear mixed model are similar to those of a linear model. One further assumption in the linear mixed model is that the mixed effects are jointly normal. Since we only have one random effect in our model (for the interaction between `year` and `region`), we look at the normal Q-Q plot of all the random intercepts of our random effect.

Besides that, we look at standard diagnostic plots for the linear model as in Figure (\@ref(fig:diagnostics)), namely the residuals vs fitted values and normal Q-Q plot for the residuals.

```{r mixeddiagnostics, fig.width=10.75, fig.height=3.5, fig.cap="Residuals vs fitted values (left), normal Q-Q plot for the residuals (middle) and normal Q-Q plot for the random intercepts of the random effect between year and region."}
# remove presinc dapprove_inc from the model, as described above
mixed_m2 = lmer(dvote ~ 
                + state 
                + dvote_poll 
                + dapprove_presinc 
                + gnp_growth_inc 
                + dvote_last 
                + dvote_last2 
                + home_state 
                + home_state_vice 
                + dmajor_leg 
                + econ_growth_inc 
                + cath_1960 
                + south 
                + south_1964 
                + deep_south_1964 
                + new_england_1964 
                + new_england_1972 
                + west_1976 
                + (1|year:region),
                data = data, 
                REML = FALSE)
# prepare the residuals dataset for diagnostic plots
data_res$residuals = resid(mixed_m2) # residual of mixed_m2
data_res$fitted = predict(mixed_m2) # fitted values of mixed_m2
# create residuals vs fitted values plot
res_vs_fit = ggplot(data_res, aes(x = fitted, y = residuals)) + 
  geom_point() + 
  labs(x = "fitted values", y = "residuals") + 
  ggtitle("Residuals vs Fitted Values")
# create qq plot
qq_plot = ggplot(data_res, aes(sample = residuals)) +
  stat_qq() + 
  stat_qq_line() + 
  labs(x = "theoretical quantiles", y = "residuals quantiles") + 
  ggtitle("Normal Q-Q Plot for Residuals")
# plot residuals vs fitted values (left) and qqplot (right)
random_effects = ranef(mixed_m2)$'year:region'[, 1]
random_effects = as.data.frame(random_effects)
qq_ran_eff = ggplot(data = random_effects, aes(sample = random_effects)) + 
  stat_qq() + 
  stat_qq_line() +
  labs(x = "theoretical quantiles", y = "random intercepts quantiles") +
  ggtitle("Normal Q-Q Plot for Random Effect")
ggarrange(res_vs_fit, qq_plot, qq_ran_eff, ncol = 3, nrow = 1)
```

The normal Q-Q plot for the residuals and the residuals vs fitted values plot look almost identical to those in Figure (\@ref(fig:diagnostics)) and hence, as in the case for the linear model from Section (\@ref(linmod)), do not suggest that a model assumption is clearly violated. Furthermore the normal Q-Q plot for the random effect in our model looks acceptable and, based on the small number of observations, we may assume that the normality assumption of our random intercepts holds.


# Parameter interpretation

In this section we examine the coefficients (fixed effects) of our final model as well as interpret some of the most important parameters. The following table contains the values of some selected coefficients.

```{r coeftable}
# create a table of some selected coefficients (dont want to display all the 
# 50 states coefficients)
coef_table = as.data.frame(summary(mixed_m2)$coefficients)
coef_table = coef_table[c(5, 51:66), ]
# only keep coefficient values coloumn
coef_table = coef_table %>%
  select(-"Std. Error", -"t value")
rownames(coef_table)[c(12:17)] = c("south", "south_1964", "deep_south_1964", "new_england_1964", "new_england_1972", "west_1976")
kable(coef_table, digits = 3, caption = "Some selected estimated coefficients (fixed effects) of the final linear mixed model.")
```

The interpretation for these coefficients is not always straightforward. Therefore we look at some examples of some interesting coefficients.

* The Democratic party candidate's share increases by 3.4 % if we look at the state California (state 5) instead of Alabama (state 0, base level of `state`).
* The Democratic party candidate's share increases by 4.33 % (0.1 * 43,3 %) if the support for the Democratic candidate in the September poll `d_vote_poll` increases by 10 %.
* The interpretation of the coefficient `dapprove_presinc` is a bit tricky. We divide it in two cases.
  - If the incumbent president is a Democrat and running for a re-election, his share increases 
  by 0.3 % (0.1 * 3 %) if the support in the July poll for the incumbent 
  president `dapprove_presinc` increases by 10 %.
  - If the incumbent president is a Republican and running for a re-election, the Democratic candidate's share decreases by 0.3 % (0.1 * 3 %) if the support in the July poll for the incumbent president `dapprove_presinc` increases by 10%.
* As before we split the interpretation of `home_state` in two cases.
  - The Democratic party candidate's share increases by 3.8 % in his home state.
  - The Democratic party candidate's share decreases by 3.8 % in the home state of the Republican candidate.
* The Democratic party candidate's share increases by 18.5 % in the deep south states if we look at the year 1964.

According to our model, `dvote_poll` (the support for the Democratic candidate in the September poll) is definitely one of the most important factors to predict the Democratic candidate's share in the election.


# Conclusion

In this report we built a statistical model for the US presidential elections between 1948 and 1992. We found that especially the September poll is a strong predictor for the later elections. For our final model, we started by using a linear model and then moved to a linear mixed model, with a random effect for the interaction between `year` and `region`. The reason why a linear mixed model might be better for this data is that we can allow for dependence between certain observations. Intuitively, it seems reasonable that observations indicating the Democratic candidate's share from the same year and in the same region influence each other. One possible explanation could be that the states from the same region have a lot more interaction with each other and possibly even share the same newspapers, which can influence the peoples voting preferences.

In general, whether to add a random effect to a model or not can be a hard question and also lies in the nature of how we look at a certain variable. For example, if we just want to account for different values in different groups without interpreting these too much, a random effect may be a good choice. If however we are interested in exactly the variation of different groups and want to quantify and describe this effect, adding a fixed effect for the variable containing these groups might be the better choice. In the case of factor variables, random effects have the advantage of not taking a full degree of freedom per level, which can be useful if there are a lot of levels present in the factor variable.
